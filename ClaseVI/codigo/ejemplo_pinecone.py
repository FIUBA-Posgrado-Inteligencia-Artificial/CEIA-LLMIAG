"""
Ejemplo de uso de Pinecone Vector Database
==========================================

Este archivo demuestra c√≥mo:
1. Crear un √≠ndice en Pinecone
2. Poblar el √≠ndice con vectores y metadatos
3. Realizar b√∫squedas por similitud

Autor: Clase VI - CEIA LLMIAG
Documentaci√≥n en espa√±ol
"""

import os
import time
import numpy as np
from typing import List, Dict, Any, Tuple
import pinecone
from sentence_transformers import SentenceTransformer
import openai


# ================================
# 1. CONFIGURACI√ìN INICIAL
# ================================

def configurar_pinecone():
    """
    Configura la conexi√≥n con Pinecone usando variables de entorno.
    
    Variables necesarias:
    - PINECONE_API_KEY: Tu clave API de Pinecone
    - PINECONE_ENVIRONMENT: El entorno de Pinecone (ej: 'us-west1-gcp')
    """
    
    # Obtener credenciales desde variables de entorno
    api_key = os.getenv("PINECONE_API_KEY")
    environment = os.getenv("PINECONE_ENVIRONMENT", "us-west1-gcp")
    
    if not api_key:
        raise ValueError("PINECONE_API_KEY no est√° configurada en las variables de entorno")
    
    # Inicializar Pinecone
    pinecone.init(
        api_key=api_key,
        environment=environment
    )
    
    print(f"‚úÖ Pinecone configurado correctamente en {environment}")
    return True


def crear_indice(nombre_indice: str, dimension: int = 384, metrica: str = "cosine"):
    """
    Crea un nuevo √≠ndice en Pinecone.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice a crear
        dimension (int): Dimensi√≥n de los vectores (depende del modelo de embedding)
        metrica (str): M√©trica de similitud ('cosine', 'euclidean', 'dotproduct')
    
    Configuraci√≥n de infraestructura:
        - Pods: Unidades de c√≥mputo paralelo que procesan las consultas
          ‚Ä¢ 1 pod = suficiente para desarrollo y proyectos peque√±os
          ‚Ä¢ M√°s pods = mayor capacidad de consultas simult√°neas pero mayor costo
        
        - R√©plicas: Copias id√©nticas del √≠ndice distribuidas geogr√°ficamente
          ‚Ä¢ 1 r√©plica = configuraci√≥n b√°sica
          ‚Ä¢ M√°s r√©plicas = mayor disponibilidad y tolerancia a fallos
        
        - Tipos de pod disponibles:
          ‚Ä¢ p1.x1: 1 vCPU, ~5GB RAM (plan gratuito/starter)
          ‚Ä¢ p1.x2: 2 vCPU, ~10GB RAM
          ‚Ä¢ p1.x4: 4 vCPU, ~20GB RAM
          ‚Ä¢ p2.x1: Optimizado para performance
    
    Returns:
        bool: True si se cre√≥ exitosamente
    """
    
    # Verificar si el √≠ndice ya existe
    indices_existentes = pinecone.list_indexes()
    
    if nombre_indice in indices_existentes:
        print(f"‚ö†Ô∏è  El √≠ndice '{nombre_indice}' ya existe")
        return True
    
    # Crear el √≠ndice
    pinecone.create_index(
        name=nombre_indice,
        dimension=dimension,
        metric=metrica,
        pods=1,  # Pods: Unidades de c√≥mputo que procesan queries. M√°s pods = mayor throughput pero mayor costo
        replicas=1,  # R√©plicas: Copias del √≠ndice para alta disponibilidad. M√°s r√©plicas = mayor disponibilidad
        pod_type="p1.x1"  # Tipo de pod: p1.x1 (gratuito, 1 vCPU), p1.x2 (2 vCPU), p2.x1 (optimizado), etc.
    )
    
    # Esperar a que el √≠ndice est√© listo
    print(f"üîÑ Creando √≠ndice '{nombre_indice}'...")
    while nombre_indice not in pinecone.list_indexes():
        time.sleep(1)
    
    print(f"‚úÖ √çndice '{nombre_indice}' creado exitosamente")
    return True


# ================================
# 2. GENERACI√ìN DE EMBEDDINGS
# ================================

class GeneradorEmbeddings:
    """
    Clase para generar embeddings usando diferentes modelos.
    """
    
    def __init__(self, modelo: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        Inicializa el generador de embeddings.
        
        Args:
            modelo (str): Nombre del modelo de Sentence Transformers
        """
        self.modelo_nombre = modelo
        self.modelo = SentenceTransformer(modelo)
        self.dimension = self.modelo.get_sentence_embedding_dimension()
        
        print(f"‚úÖ Modelo '{modelo}' cargado (dimensi√≥n: {self.dimension})")
    
    def generar_embedding(self, texto: str) -> List[float]:
        """
        Genera embedding para un texto individual.
        
        Args:
            texto (str): Texto a convertir en embedding
            
        Returns:
            List[float]: Vector de embedding
        """
        embedding = self.modelo.encode(texto)
        return embedding.tolist()
    
    def generar_embeddings_lote(self, textos: List[str]) -> List[List[float]]:
        """
        Genera embeddings para m√∫ltiples textos de manera eficiente.
        
        Args:
            textos (List[str]): Lista de textos
            
        Returns:
            List[List[float]]: Lista de vectores de embedding
        """
        embeddings = self.modelo.encode(textos)
        return [emb.tolist() for emb in embeddings]


# ================================
# 3. POBLACI√ìN DEL √çNDICE
# ================================

def poblar_indice_ejemplo(nombre_indice: str, generador: GeneradorEmbeddings):
    """
    Puebla el √≠ndice con datos de ejemplo.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice de Pinecone
        generador (GeneradorEmbeddings): Instancia del generador de embeddings
    """
    
    # Conectar al √≠ndice
    indice = pinecone.Index(nombre_indice)
    
    # Datos de ejemplo: documentos sobre inteligencia artificial
    documentos_ejemplo = [
        {
            "id": "doc_001",
            "texto": "La inteligencia artificial es una rama de la inform√°tica que busca crear m√°quinas capaces de realizar tareas que normalmente requieren inteligencia humana.",
            "categoria": "definicion",
            "fecha": "2024-01-15"
        },
        {
            "id": "doc_002", 
            "texto": "Los modelos de lenguaje grandes como GPT-4 utilizan arquitecturas transformer para procesar y generar texto de manera coherente.",
            "categoria": "modelos",
            "fecha": "2024-01-16"
        },
        {
            "id": "doc_003",
            "texto": "El aprendizaje autom√°tico es un subconjunto de la IA que permite a las m√°quinas aprender patrones a partir de datos sin ser programadas expl√≠citamente.",
            "categoria": "machine_learning",
            "fecha": "2024-01-17"
        },
        {
            "id": "doc_004",
            "texto": "Las redes neuronales artificiales est√°n inspiradas en el funcionamiento del cerebro humano y consisten en capas de neuronas interconectadas.",
            "categoria": "redes_neuronales",
            "fecha": "2024-01-18"
        },
        {
            "id": "doc_005",
            "texto": "La b√∫squeda vectorial permite encontrar documentos similares comparando la distancia entre vectores en un espacio multidimensional.",
            "categoria": "busqueda_vectorial",
            "fecha": "2024-01-19"
        }
    ]
    
    print(f"üîÑ Poblando √≠ndice con {len(documentos_ejemplo)} documentos...")
    
    # Generar embeddings para todos los textos
    textos = [doc["texto"] for doc in documentos_ejemplo]
    embeddings = generador.generar_embeddings_lote(textos)
    
    # Preparar datos para inserci√≥n en lotes
    vectors_para_insertar = []
    
    for i, doc in enumerate(documentos_ejemplo):
        vector_data = {
            "id": doc["id"],
            "values": embeddings[i],
            "metadata": {
                "texto": doc["texto"],
                "categoria": doc["categoria"],
                "fecha": doc["fecha"],
                "longitud": len(doc["texto"])
            }
        }
        vectors_para_insertar.append(vector_data)
    
    # Insertar vectores en el √≠ndice
    indice.upsert(vectors=vectors_para_insertar)
    
    # Verificar estad√≠sticas del √≠ndice
    estadisticas = indice.describe_index_stats()
    print(f"‚úÖ √çndice poblado exitosamente")
    print(f"   üìä Total de vectores: {estadisticas['total_vector_count']}")
    print(f"   üìè Dimensi√≥n: {estadisticas['dimension']}")
    
    return True


# ================================
# 4. B√öSQUEDAS EN EL √çNDICE
# ================================

def buscar_documentos_similares(
    nombre_indice: str, 
    consulta: str, 
    generador: GeneradorEmbeddings,
    top_k: int = 3,
    filtro_metadata: Dict = None
) -> List[Dict[str, Any]]:
    """
    Realiza una b√∫squeda por similitud en el √≠ndice.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice de Pinecone
        consulta (str): Texto de consulta para buscar
        generador (GeneradorEmbeddings): Generador de embeddings
        top_k (int): N√∫mero de resultados m√°s similares a devolver
        filtro_metadata (Dict): Filtros opcionales por metadata
        
    Returns:
        List[Dict]: Lista de documentos similares con scores
    """
    
    # Conectar al √≠ndice
    indice = pinecone.Index(nombre_indice)
    
    # Generar embedding para la consulta
    print(f"üîç Buscando documentos similares a: '{consulta}'")
    embedding_consulta = generador.generar_embedding(consulta)
    
    # Realizar la b√∫squeda
    resultados = indice.query(
        vector=embedding_consulta,
        top_k=top_k,
        include_metadata=True,
        filter=filtro_metadata
    )
    
    # Procesar y formatear resultados
    documentos_encontrados = []
    
    print(f"\nüìã Resultados encontrados ({len(resultados['matches'])}):")
    print("=" * 80)
    
    for i, match in enumerate(resultados['matches'], 1):
        documento = {
            "posicion": i,
            "id": match["id"],
            "score": round(match["score"], 4),
            "texto": match["metadata"]["texto"],
            "categoria": match["metadata"]["categoria"],
            "fecha": match["metadata"]["fecha"]
        }
        
        documentos_encontrados.append(documento)
        
        # Mostrar resultado formateado
        print(f"{i}. ID: {documento['id']}")
        print(f"   üìä Score: {documento['score']}")
        print(f"   üè∑Ô∏è  Categor√≠a: {documento['categoria']}")
        print(f"   üìÖ Fecha: {documento['fecha']}")
        print(f"   üìù Texto: {documento['texto'][:100]}...")
        print("-" * 80)
    
    return documentos_encontrados


def buscar_con_filtros_ejemplo(nombre_indice: str, generador: GeneradorEmbeddings):
    """
    Demuestra b√∫squedas con filtros de metadata.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice
        generador (GeneradorEmbeddings): Generador de embeddings
    """
    
    print("\nüîç EJEMPLO DE B√öSQUEDAS CON FILTROS")
    print("=" * 50)
    
    # B√∫squeda 1: Sin filtros
    print("\n1Ô∏è‚É£ B√∫squeda general sobre 'aprendizaje de m√°quinas':")
    buscar_documentos_similares(
        nombre_indice, 
        "aprendizaje de m√°quinas y algoritmos", 
        generador,
        top_k=3
    )
    
    # B√∫squeda 2: Con filtro por categor√≠a
    print("\n2Ô∏è‚É£ B√∫squeda filtrada por categor√≠a 'modelos':")
    filtro_categoria = {"categoria": {"$eq": "modelos"}}
    buscar_documentos_similares(
        nombre_indice,
        "transformers y procesamiento de texto",
        generador,
        top_k=2,
        filtro_metadata=filtro_categoria
    )
    
    # B√∫squeda 3: Con filtro por fecha
    print("\n3Ô∏è‚É£ B√∫squeda de documentos recientes (despu√©s del 2024-01-17):")
    filtro_fecha = {"fecha": {"$gte": "2024-01-17"}}
    buscar_documentos_similares(
        nombre_indice,
        "redes neuronales y vectores",
        generador,
        top_k=5,
        filtro_metadata=filtro_fecha
    )


# ================================
# 5. GESTI√ìN DEL √çNDICE
# ================================

def obtener_estadisticas_indice(nombre_indice: str):
    """
    Muestra estad√≠sticas detalladas del √≠ndice.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice
    """
    
    indice = pinecone.Index(nombre_indice)
    estadisticas = indice.describe_index_stats()
    
    print(f"\nüìä ESTAD√çSTICAS DEL √çNDICE '{nombre_indice}'")
    print("=" * 50)
    print(f"üì¶ Total de vectores: {estadisticas.get('total_vector_count', 0)}")
    print(f"üìè Dimensi√≥n: {estadisticas.get('dimension', 0)}")
    
    # Mostrar estad√≠sticas por namespace si existen
    if 'namespaces' in estadisticas:
        print(f"üè∑Ô∏è  Namespaces:")
        for namespace, stats in estadisticas['namespaces'].items():
            print(f"   - {namespace}: {stats.get('vector_count', 0)} vectores")


def eliminar_documentos(nombre_indice: str, ids_documentos: List[str]):
    """
    Elimina documentos espec√≠ficos del √≠ndice.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice
        ids_documentos (List[str]): Lista de IDs a eliminar
    """
    
    indice = pinecone.Index(nombre_indice)
    
    print(f"üóëÔ∏è  Eliminando {len(ids_documentos)} documentos...")
    indice.delete(ids=ids_documentos)
    
    print(f"‚úÖ Documentos eliminados: {', '.join(ids_documentos)}")


def limpiar_indice_completo(nombre_indice: str):
    """
    Elimina todos los vectores del √≠ndice.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice a limpiar
    """
    
    indice = pinecone.Index(nombre_indice)
    
    print(f"üßπ Limpiando √≠ndice '{nombre_indice}' completamente...")
    indice.delete(delete_all=True)
    
    print("‚úÖ √çndice limpiado exitosamente")


def eliminar_indice(nombre_indice: str):
    """
    Elimina completamente un √≠ndice de Pinecone.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice a eliminar
    """
    
    print(f"üóëÔ∏è  Eliminando √≠ndice '{nombre_indice}'...")
    pinecone.delete_index(nombre_indice)
    
    print(f"‚úÖ √çndice '{nombre_indice}' eliminado exitosamente")


# ================================
# 6. FUNCI√ìN PRINCIPAL DE EJEMPLO
# ================================

def ejecutar_ejemplo_completo():
    """
    Ejecuta un ejemplo completo de uso de Pinecone:
    1. Configuraci√≥n
    2. Creaci√≥n del √≠ndice
    3. Poblaci√≥n con datos
    4. B√∫squedas de ejemplo
    5. Limpieza (opcional)
    """
    
    # Configuraci√≥n
    nombre_indice = "ejemplo-ceia-llmiag"
    
    try:
        print("üöÄ INICIANDO EJEMPLO DE PINECONE")
        print("=" * 50)
        
        # 1. Configurar conexi√≥n
        configurar_pinecone()
        
        # 2. Inicializar generador de embeddings
        generador = GeneradorEmbeddings()
        
        # 3. Crear √≠ndice
        crear_indice(nombre_indice, dimension=generador.dimension)
        
        # 4. Poblar √≠ndice con datos de ejemplo
        poblar_indice_ejemplo(nombre_indice, generador)
        
        # 5. Mostrar estad√≠sticas
        obtener_estadisticas_indice(nombre_indice)
        
        # 6. Realizar b√∫squedas de ejemplo
        buscar_con_filtros_ejemplo(nombre_indice, generador)
        
        # 7. B√∫squeda personalizada
        print("\nüéØ B√öSQUEDA PERSONALIZADA")
        print("=" * 30)
        consulta_personalizada = "¬øQu√© son las redes neuronales?"
        resultados = buscar_documentos_similares(
            nombre_indice, 
            consulta_personalizada, 
            generador,
            top_k=2
        )
        
        print(f"\n‚úÖ EJEMPLO COMPLETADO EXITOSAMENTE")
        print(f"üìÅ √çndice '{nombre_indice}' est√° listo para usar")
        
        # Opcional: Comentar la siguiente l√≠nea si quieres mantener el √≠ndice
        # eliminar_indice(nombre_indice)
        
    except Exception as e:
        print(f"‚ùå Error durante la ejecuci√≥n: {str(e)}")
        raise


# ================================
# 7. UTILIDADES ADICIONALES
# ================================

def crear_indice_desde_documentos(
    nombre_indice: str,
    documentos: List[Dict[str, Any]],
    campo_texto: str = "texto",
    modelo_embedding: str = "sentence-transformers/all-MiniLM-L6-v2"
):
    """
    Funci√≥n helper para crear un √≠ndice directamente desde una lista de documentos.
    
    Args:
        nombre_indice (str): Nombre del √≠ndice a crear
        documentos (List[Dict]): Lista de documentos con texto y metadata
        campo_texto (str): Nombre del campo que contiene el texto
        modelo_embedding (str): Modelo para generar embeddings
    
    Returns:
        bool: True si se cre√≥ exitosamente
    """
    
    # Configurar y crear componentes
    configurar_pinecone()
    generador = GeneradorEmbeddings(modelo_embedding)
    crear_indice(nombre_indice, dimension=generador.dimension)
    
    # Conectar al √≠ndice
    indice = pinecone.Index(nombre_indice)
    
    # Procesar documentos en lotes
    lote_size = 100
    total_procesados = 0
    
    print(f"üîÑ Procesando {len(documentos)} documentos en lotes de {lote_size}...")
    
    for i in range(0, len(documentos), lote_size):
        lote_docs = documentos[i:i + lote_size]
        
        # Generar embeddings para el lote
        textos_lote = [doc[campo_texto] for doc in lote_docs]
        embeddings_lote = generador.generar_embeddings_lote(textos_lote)
        
        # Preparar vectores para inserci√≥n
        vectores_lote = []
        for j, doc in enumerate(lote_docs):
            # Generar ID si no existe
            doc_id = doc.get("id", f"doc_{i+j:06d}")
            
            # Preparar metadata (excluir el texto para evitar duplicaci√≥n)
            metadata = {k: v for k, v in doc.items() if k != campo_texto and k != "id"}
            metadata["texto"] = doc[campo_texto]  # Incluir texto en metadata
            
            vector_data = {
                "id": doc_id,
                "values": embeddings_lote[j],
                "metadata": metadata
            }
            vectores_lote.append(vector_data)
        
        # Insertar lote
        indice.upsert(vectors=vectores_lote)
        total_procesados += len(lote_docs)
        
        print(f"   ‚úÖ Procesados {total_procesados}/{len(documentos)} documentos")
    
    print(f"üéâ √çndice '{nombre_indice}' creado con {total_procesados} documentos")
    return True


if __name__ == "__main__":
    """
    Para ejecutar este ejemplo, aseg√∫rate de:
    
    1. Instalar las dependencias:
       pip install pinecone-client sentence-transformers openai numpy
    
    2. Configurar variables de entorno:
       export PINECONE_API_KEY="tu-api-key-aqui"
       export PINECONE_ENVIRONMENT="us-west1-gcp"  # o tu regi√≥n
    
    3. Ejecutar el script:
       python ejemplo_pinecone.py
    """
    
    # Verificar si las variables de entorno est√°n configuradas
    if not os.getenv("PINECONE_API_KEY"):
        print("‚ùå PINECONE_API_KEY no est√° configurada")
        print("üí° Configura tus variables de entorno antes de ejecutar:")
        print("   export PINECONE_API_KEY='tu-api-key'")
        print("   export PINECONE_ENVIRONMENT='tu-region'")
        exit(1)
    
    # Ejecutar ejemplo completo
    ejecutar_ejemplo_completo()